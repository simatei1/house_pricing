{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary tools of trade\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer as si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to load the data into our worksheet\n",
    "X_full=pd.read_csv('train.csv')\n",
    "X_test_full=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to predict the sale price(respose variables)\n",
    "y=X_full.SalePrice\n",
    "#we select our relevant columns for our features\n",
    "features=['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "#we fit our features to make a relevat data_frame\n",
    "X=X_full[features].copy()\n",
    "#we neeed to create a data_frame for our test features\n",
    "X_test=X_test_full[features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to split data\n",
    "X_train,X_valid, y_train, y_valid=tts(X,y,train_size=0.8,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we need to create random forest models\n",
    "#defining the models\n",
    "model_1= rfr(n_estimators=50, random_state=0)\n",
    "model_2 = rfr(n_estimators=100, random_state=0)\n",
    "model_3 = rfr(n_estimators=100, criterion='mae', random_state=0)\n",
    "model_4 = rfr(n_estimators=200, min_samples_split=20, random_state=0)\n",
    "model_5 = rfr(n_estimators=100, max_depth=7, random_state=0)\n",
    "\n",
    "models = [model_1, model_2, model_3, model_4, model_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 MAE: 24015\n",
      "Model 2 MAE: 23740\n",
      "Model 3 MAE: 23528\n",
      "Model 4 MAE: 23996\n",
      "Model 5 MAE: 23706\n"
     ]
    }
   ],
   "source": [
    "#To select the best model out of the five, we define a function score_model()  which  returns the mae\n",
    "\n",
    "# Function for comparing different models\n",
    "def score_model(model, X_t=X_train, X_v=X_valid, y_t=y_train, y_v=y_valid):\n",
    "    model.fit(X_t, y_t)\n",
    "    preds = model.predict(X_v)\n",
    "    return mean_absolute_error(y_v, preds)\n",
    "\n",
    "for i in range(0, len(models)):\n",
    "    mae = score_model(models[i])\n",
    "    print(\"Model %d MAE: %d\" % (i+1, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = rfr(n_estimators=10, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to get the columns with missing values\n",
    "cols_missing=[col for col in X_train.columns\n",
    "              if X_train[col].isnull().any()]\n",
    "#drop columns in training and validation data\n",
    "reduced_X_train=X_train.drop(cols_missing, axis=1)\n",
    "reduced_X_valid=X_valid.drop(cols_missing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Imputation):\n",
      "25474.17279843444\n"
     ]
    }
   ],
   "source": [
    "#Impuitation as as way of dealing with missing values\n",
    "my_imputer=si()\n",
    "imputed_X_train=pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid=pd.DataFrame(my_imputer.transform(X_valid))\n",
    "#Imputation  removed column names, now we need to put them back together\n",
    "imputed_X_train.columns=X_train.columns\n",
    "imputed_X_valid.columns=X_valid.columns\n",
    "\n",
    "#checking the effect on the MAE:\n",
    "print(\"MAE from Approach 2 (Imputation):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_test = pd.DataFrame(my_imputer.fit_transform(X_test))\n",
    "\n",
    "# Fill in the line below: get test predictions\n",
    "preds_test = model_3.predict(final_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
